* Gradient Descent
Our GradientDescent function is located at:
https://github.com/jguzman-tech/gradient-descent/blob/master/main.py
** 1. How to run
*** 1.1. First clone the repo 
git clone https://github.com/jguzman-tech/gradient-descent/
*** 1.2. Create an arbitrary directory
#+BEGIN_SRC
mkdir ./.venv
#+END_SRC
*** 1.3. Create a virtual environment
#+BEGIN_SRC
python3 -m venv ./.venv
#+END_SRC
*** 1.4. Activate the virtual environment
#+BEGIN_SRC
. ./.venv/bin/activate
#+END_SRC
*** 1.5. Install module requirements
#+BEGIN_SRC
pip3 install -r ./requirements.txt
#+END_SRC
*** 1.6. Execute
#+BEGIN_SRC
python3 main.py <dataset> <stepSize> <maxiterations> <seed>
#+END_SRC
The valid dataset values are: spam.data, SAheart.data, and zip.train.
stepSize must be a float
maxiterations must be an int
seed must be an int

If successful then the program will create an error plot, a mean logistic loss,
and a ROC curve csv file for the dataset. The filenames will include the
arguments that you provided the program.

You can generate ROC curve graphs by passing ROC curve npy filenames as
command-line arguments to our roc_curve_grapher.py file. These npy files are
compressed versions of numpy arrays.

#+BEGIN_SRC
python3 roc_curve_grapher.py <roc-curve-1.npy> <roc-curve-2.npy> ...
#+END_SRC

**** Note:
Only execute these programs in the gradient-descent directory because the
program will attempt to use relative paths to ./figures/ and ./roc-data/
** 2. Final Report results
All figures from our final report are located in ./final-report-figs/

*** 2.1. Reproduce our results:
Again this is assuming a linux system. If you're a windows user then you'll have
to figure out your powershell or cmd command equivalents. On my computer the
reproduce.sh file took just under 5 minutes to execute.
**** 2.1.1. Setup your environment as described in '1. How to run'
**** 2.2.1. Execute ./reproduce.sh
** 3. About
This repository was made to fulfill the requirements of Project 1 of NAU's CS499: Deep
Learning. 

The Gradient Descent algorithm is a simple concept in Euclidean Space. In
Euclidean Space, for each iteration you move in the -f'(x) direction which will
eventually lead you to a critical point. Our goal is to find the minimum of
f(x), doing so will allow us to classify a data point as a 0 or a 1 with high
accuracy.
